1. What is Docker?

Docker is an open-source containerization platform that allows you to package an application along with its dependencies 
(libraries, config, runtime) into a lightweight, portable container.
These containers can run consistently across different environments (developer laptop, test, production, cloud).


2. Why are you using Docker?

I use Docker mainly because:
Consistency: It eliminates the “works on my machine” problem. The same container runs everywhere.
Lightweight: Containers share the host OS kernel, so they are faster and use fewer resources compared to virtual machines.
Faster deployment: Applications start in seconds because containers are pre-packaged.
Scalability: Works very well with orchestration tools like Kubernetes for scaling microservices.
Isolation: Each container runs independently, so multiple applications/services can coexist without conflicts.
Portability: I can easily move applications between environments (dev → test → prod, or on-prem → cloud).

Example (how I’d put it in an interview):
"Docker is a containerization tool that helps me package applications with dependencies into portable containers.
 I use it because it ensures consistency across environments, makes deployments faster, 
 reduces resource usage compared to VMs, and integrates well with CI/CD and Kubernetes for scaling."

3. Can you describe a situation where you used Docker to solve a specific problem?

"In one of my projects, we faced issues with inconsistent environments —
 the app worked on one machine but failed on another due to dependency mismatches.
 I solved this by containerizing the application using Docker. I wrote a Dockerfile 
 to standardize dependencies and used Docker Compose to run the app along with its database 
 in a single stack. For development, I used bind mounts for live code changes, and for production, 
 I switched to volumes for persistent data. This ensured consistency across dev, staging, and prod. 
 As a result, we eliminated the ‘works on my machine’ problem and reduced deployment issues significantly."

4. Can you explain how Docker container differs from virtual machines?

Docker Containers
"Docker containers are lightweight, portable units that package an application with its dependencies 
 and run on top of the host operating system’s kernel. They don’t need a full guest OS, which makes 
 them fast to start, efficient in resource usage, and easy to scale. Containers are ideal for microservices, 
 cloud-native applications, and CI/CD pipelines where speed, portability, and consistency across environments are critical."

Virtual Machines (VMs)
"Virtual machines run on a hypervisor and include a full guest operating system along with the 
application and its dependencies. This makes them heavier, more resource-intensive, and slower to 
boot compared to containers. However, VMs provide stronger isolation and allow running multiple,
different operating systems on the same host, which is useful for legacy applications 
or workloads that require complete OS-level separation."

5.You're in charge of maintaining Docker environments in your company and You've noticed many 
stopped containers and unused networks taking up space. 
Describe how you would clean up these resources effectively to optimize the Docker environment.?

The docker prune command is used to clean up unused Docker resources, such as containers, 
volumes, networks, and images. It helps reclaim disk space and tidy up 
the Docker environment by removing objects that are not in use.

There are different types of `docker prune` commands:

- `docker container prune`: Removes stopped containers.
- `docker volume prune`: Deletes unused volumes.
- `docker network prune`: Cleans up unused networks.
- `docker image prune`: Removes unused images.
- docker system prune --volumes
- docker system prune -a : 
remove all in sing cmd
Removes all stopped containers
Removes all unused networks (not used by any container)
Removes all dangling images (images not tagged or referenced)
Removes all unused images (not just dangling ones — that’s what the -a flag does)

Running **`docker system prune`** combines these functionalities into one command, 
ensuring that Docker removes any resources not associated with a running container.
**** On production hosts without double-checking, because you might remove images/containers that are needed later.

6.You're working on a project that requires Docker containers to persistently store data
How do you handle persistent storage in Docker?

"By default, data inside a Docker container is ephemeral, meaning it’s lost when the container 
stops or is removed. To handle persistent storage, I use Docker volumes or bind mounts depending on the use case.
Volumes: These are Docker-managed and stored under /var/lib/docker/volumes/. They are the best choice for production because they are portable, managed by Docker, and can be easily backed up and shared between containers.
Example:
docker run -d --name db -v db_data:/var/lib/mysql mysql:latest

Here, db_data is a named volume that persists even if the container is removed.
Bind Mounts: These map a host directory into the container. They are useful for development when I want live code changes to reflect inside the container. Example:
docker run -d -v $(pwd)/app:/usr/src/app myapp
"In production, I prefer volumes because they are more secure, portable, and independent of the host’s 
filesystem structure. For backups or migration, I can also use helper containers to copy data in and out of volumes safely."

7.A company wants to create thousands of Containers. Is there a limit on how many containers you can run in Docker?

"Docker itself does not impose a hard limit on the number of containers you can run. 
The practical limit depends on the host machine’s resources like CPU, memory, disk I/O, 
and network capacity. For example, if the containers are lightweight, you might run thousands on a powerful server, 
but if they are heavy (like full databases), you may only run a few. Scaling beyond a single host is usually managed 
with orchestration tools like Kubernetes or Docker Swarm, which distribute containers across multiple nodes. 
So the real limit is not Docker itself, but the available resources and the orchestration strategy you use."