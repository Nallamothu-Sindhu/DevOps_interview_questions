-> what is terraform and how its work?

Terraform is an Infrastructure as Code (IaC) tool that allows us to provision, configure, and manage infrastructure across multiple 
 cloud providers like AWS, Azure, GCP, and on-prem.

It works in a declarative way:
We define the desired infrastructure in .tf files (e.g., VMs, networks, storage).
Terraform builds a plan by comparing the current state (from the state file + cloud) with the desired state.
On terraform apply, it executes changes to bring real infrastructure in sync with the code.
It maintains a state file to track resources and dependencies.
------------------------------------------------------------------------------------------------------------------------------------------------------------------

-> terraform init, plan , apply, destroy?

1. terraform init
Purpose: Initialize a Terraform working directory.
Downloads required providers (like AWS, Azure, GCP).
Initializes the backend for storing the state file.
Must be run once before any other Terraform command.
Example:
terraform init
Output: “Terraform has been successfully initialized!”
2. terraform plan
Purpose: Preview the changes Terraform will make.
Compares your current state with your configuration files (.tf).
Shows which resources will be created, updated, or destroyed.
No changes are made yet — it’s only a dry run.
Example:
terraform plan
Output:
“Plan: 2 to add, 0 to change, 0 to destroy.”
3. terraform apply
Purpose: Actually apply the planned changes.
Executes the actions shown in the plan.
Creates, modifies, or deletes resources in your cloud provider.
Asks for confirmation before running (unless you use -auto-approve).
Example:
terraform apply
Output:
“Apply complete! Resources: 2 added, 0 changed, 0 destroyed.”
4. terraform destroy
Purpose: Remove all resources managed by Terraform.
Destroys all infrastructure defined in your .tf files.
Useful for cleaning up environments (e.g., dev or test).
Example:
terraform destroy
Output:
“Destroy complete! Resources: 2 destroyed.”
------------------------------------------------------------------------------------------------------------------------------------------------------------------
-> in your organization which terraform version your using currently?

In our organization, we’re currently using Terraform v1.5.x (or v1.6.x), since it’s stable and compatible with our existing modules and providers. We regularly test new versions in a staging environment before upgrading, to ensure backward compatibility and avoid breaking changes.”
------------------------------------------------------------------------------------------------------------------------------------------------------------------
-> what are the variables, types of variables and how do you pass variable in run time in terraform? 

Variables in Terraform are used to make configurations dynamic and reusable.
Instead of hardcoding values (like instance types or region), you define them as variables and assign values separately.
Types of Variables
-- String – Single text value
variable "region" {
  type    = string
  default = "us-east-1"
}
-- Number – Numeric value
variable "instance_count" {
  type    = number
  default = 2
}
-- Bool – True or false
variable "enable_monitoring" {
  type    = bool
  default = true
}
-- List – Ordered list of values
variable "azs" {
  type    = list(string)
  default = ["us-east-1a", "us-east-1b"]
}
-- Map – Key-value pairs
variable "tags" {
  type = map(string)
  default = {
    Environment = "dev"
    Owner       = "teamA"
  }
}

Ways to Pass Variables at Runtime
You can pass variables in four main ways:
Using -var option (CLI):
terraform apply -var="region=us-west-2"
Using .tfvars file:
region = "us-west-2"
instance_count = 3
Run with:
terraform apply -var-file="dev.tfvars"
Using Environment Variables:
export TF_VAR_region="us-west-2"
terraform apply
Using Default Values:
If a variable has a default, Terraform uses it automatically.
variable "instance_type" {
  type    = string
  default = "t2.small"
}
------------------------------------------------------------------------------------------------------------------------------------------------------------------
-> remote backend in terraform?

A backend in Terraform determines where the state file is stored.
By default, Terraform uses a local backend (state file stored locally).
A remote backend stores the state in a centralized location, which is important for team collaboration and security.
Benefits of Remote Backend
Collaboration: Multiple team members can work on the same infrastructure safely.
State Locking: State locking stops multiple updates at once.
Versioning: Versioning keeps history so you can restore old state files.
Security: State files can contain sensitive data; remote backends often support encryption.

For Azure Example
terraform {
  backend "azurerm" {
    resource_group_name  = "rg-terraform"
    storage_account_name = "terraformstate123"
    container_name       = "tfstate"
    key                  = "dev.terraform.tfstate"
  }
}
------------------------------------------------------------------------------------------------------------------------------------------------------------------
-> what are the modules, why we are using it and different kinds of modules in terraform?

A module in Terraform is a container for multiple resources that are used together.
It’s like a reusable block of code — instead of writing the same resource code again and again, you define it once as a module and use it wherever needed.
Why We Use Modules
Reusability – Use the same infrastructure code for multiple environments (dev, test, prod).
Organization – Keep Terraform code clean and modular instead of one big file.
Consistency – Apply standard infrastructure patterns across teams.
Scalability – Makes managing large infrastructures easier.
Types of Modules in Terraform
| Type                     | Description                                                                                 |
| ------------------------ | ------------------------------------------------------------------------------------------- |
| **Root Module**          | The main working directory that contains `.tf` files you run (`terraform apply` on).        |
| **Child Module**         | Called from within another module or root module using the `module` block.                  |
| **Public Module**        | Modules available from the **Terraform Registry** (like ready-made AWS VPC or EC2 modules). |
| **Private/Local Module** | Custom modules stored in your local repo or private registry for internal use.              |

main.tf:
# Create Resource Group
module "rg" {
  source              = "./modules/resource_group"
  resource_group_name = "app-rg"
  location            = "East US"
}

# Create Virtual Network
module "vnet" {
  source              = "./modules/vnet"
  vnet_name           = "app-vnet"
  address_space       = ["10.0.0.0/16"]
  location            = module.rg.location
  resource_group_name = module.rg.name
}

# Create Virtual Machine
module "vm" {
  source              = "./modules/vm"
  vm_name             = "app-vm"
  location            = module.rg.location
  resource_group_name = module.rg.name
  subnet_id           = module.vnet.subnet_id
  admin_username      = "azureuser"
  admin_password      = "Password@123"
}

modules/resource_group/main.tf:

resource "azurerm_resource_group" "rg" {
  name     = var.resource_group_name
  location = var.location
}

output "name" {
  value = azurerm_resource_group.rg.name
}

output "location" {
  value = azurerm_resource_group.rg.location
}
------------------------------------------------------------------------------------------------------------------------------------------------------------------
-> we deleted the state file what will happened we again do terraform plan , apply?

The Terraform state file (terraform.tfstate) keeps a record of what resources already exist in your cloud.
If you delete it, Terraform forgets everything it previously created.
Now, if you run terraform plan after deleting the state file:
Terraform no longer knows any existing resources.
So it will compare your configuration with an empty state and think:
“No resources exist — I need to create them all again.”
Output:
Plan: 3 to add, 0 to change, 0 to destroy.
Even though your infrastructure already exists in Azure/AWS, Terraform doesn’t realize that — it wants to recreate everything.
If you then run terraform apply:
Terraform will try to create all those resources again, which can cause:
Duplicate resources (like another VM or VNet with the same name)
Errors (if resource names must be unique)
Loss of previous tracking (Terraform no longer manages your old resources)
How to Fix (Best Practice)
If you accidentally delete the state file but your infrastructure still exists:
Use
terraform import <resource_address> <resource_id>
to re-import existing resources into a new state file.
Example:
terraform import azurerm_resource_group.rg /subscriptions/<id>/resourceGroups/my-rg
Or restore the state file from your remote backend backup (e.g., S3 versioning, Terraform Cloud).
------------------------------------------------------------------------------------------------------------------------------------------------------------------
-> Can you destroy only one resource in Terraform? If yes, how?

Yes, we can destroy a single specific resource in Terraform using the -target flag with the terraform destroy command.
For example, if I have a resource like this:
resource "azurerm_storage_account" "storage" {
  name                     = "mystorage12345"
  resource_group_name      = azurerm_resource_group.rg.name
  location                 = azurerm_resource_group.rg.location
  account_tier             = "Standard"
  account_replication_type = "LRS"
}
and I only want to delete the storage account — not the resource group —
I’ll run this command:
terraform destroy -target=azurerm_storage_account.storage
This will plan and destroy only that specific resource without affecting others.
However, I’ll also mention that the -target option should be used carefully — it’s mainly for testing or selective clean-up, not regular use, because it can lead to inconsistent states if dependencies exist.
------------------------------------------------------------------------------------------------------------------------------------------------------------------
-> what is lifecycle block in terraform? when we are using it?

The lifecycle block in Terraform is used inside a resource to control how Terraform creates, updates, or destroys that resource.
resource "azurerm_storage_account" "example" {
  name                     = "mystorage12345"
  resource_group_name      = azurerm_resource_group.rg.name
  location                 = "East US"
  account_tier             = "Standard"
  account_replication_type = "LRS"

  lifecycle {
    prevent_destroy = true
    ignore_changes  = [tags]
    create_before_destroy = true
  }
}

| Argument                  | Description                                                                                                |
| ------------------------- | ---------------------------------------------------------------------------------------------------------- |
| **prevent_destroy**       | Prevents Terraform from accidentally deleting the resource. Helpful for critical resources like databases. |
| **ignore_changes**        | Ignores specific attribute updates so Terraform doesn’t trigger an unnecessary change.                     |
| **create_before_destroy** | Creates a new resource first before destroying the old one (helps avoid downtime).                         |

When Do We Use It?

When we want to protect critical resources from deletion (prevent_destroy).
When changes made outside Terraform should be ignored (ignore_changes).[manually updating tags, sizes etc]
When we need zero downtime during updates (create_before_destroy).

------------------------------------------------------------------------------------------------------------------------------------------------------------------

-> You are managing a complex infrastructure with multiple components, and you need to ensure that Terraform deploys 
all resources in the correct order?

In Terraform, the depends_on argument is used to explicitly define a dependency between resources.
It ensures that one resource is created or destroyed only after another specific resource has been created or destroyed —
 even if there’s no direct reference between them.

Example:
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_subnet" "main" {
  vpc_id     = aws_vpc.main.id
  cidr_block = "10.0.1.0/24"
}

resource "aws_instance" "app" {
  ami           = var.ami_id
  instance_type = "t2.micro"
  subnet_id     = aws_subnet.main.id
  depends_on    = [aws_vpc.main]
}
------------------------------------------------------------------------------------------------------------------------------------------------------------------
--> You want to create an instance (AWS EC2 / Azure VM) using Terraform and then execute a shell script on the instance after 
it has been created. How can you achieve this?

“We can achieve this using the provisioner block in Terraform.
The remote-exec provisioner allows us to run shell commands or scripts on the instance after it’s created, and the file provisioner 
is used to upload files to the VM before running them.”

file – to upload a file from local to the instance.
remote-exec – to run commands or shell scripts inside the remote instance.
local-exec – to run commands locally on the machine where Terraform is executed (like triggering Ansible or scripts).

  provisioner "file" {
    source      = "setup.sh"
    destination = "/tmp/setup.sh"
  }

  # Run commands on VM
  provisioner "remote-exec" {
    inline = [
      "chmod +x /tmp/setup.sh",
      "sudo /tmp/setup.sh"
    ]
  }

  # Run command locally (on Terraform host)
  provisioner "local-exec" {
    command = "echo VM deployed successfully > deploy.log"
  }

  connection {
    type        = "ssh"
    user        = "ec2-user"
    private_key = file("~/.ssh/id_rsa")
    host        = self.public_ip
  }

------------------------------------------------------------------------------------------------------------------------------------------------------------------
--> You have an existing infrastructure on AWS/azure, and you need to use Terraform to manage it. How would you import these 
resources into your Terraform configuration?

“We can use the terraform import command to bring existing resources into Terraform state so Terraform can start managing them.
First, we define the same resource block in our Terraform code, then use the import command to link that existing AWS resource 
to Terraform’s state file.”

Example (AWS):
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
}


Then import the existing EC2 instance using its resource ID:

terraform import aws_instance.web i-0abcd1234ef567890


Terraform then maps that real AWS instance to your Terraform configuration.

Example (Azure):
resource "azurerm_resource_group" "rg" {
  name     = "my-rg"
  location = "East US"
}


Then import it using:

terraform import azurerm_resource_group.rg /subscriptions/xxxx/resourceGroups/my-rg
--------------------------------------------------------------------------------------------------------------------------------------------------
-->  You are working with multiple environments (e.g., dev, prod) and want to avoid duplicating code. 
How would you structure your Terraform configurations to achieve code reuse?

“To avoid duplicating code across environments, I use Terraform modules.
I’ll create a common reusable module for resources like VMs, networks, or storage, and then call that module separately 
for each environment — dev, test, or prod — by passing different variables.
This helps in maintaining consistency and makes code easy to manage.”
module "compute" {
  source     = "../../modules/compute"
  vm_name    = "dev-vm"
  vm_size    = "Standard_B1s"
  environment = "dev"
}
---------------------------------------------------------------------------------------------------------------------------------------------------
-->  Describe a situation where you might need to use the terraform remote backend, and what advantages does it offer in state management?

We use a remote backend when multiple team members are managing the same Terraform project.
It stores the Terraform state file in a remote location like AWS S3 or Azure Storage Account instead of locally.
This helps in team collaboration, state locking, version control, and also prevents accidental deletion or corruption of the local state file.”

-------------------------------------------------------------------------------------------------------------------------------------------------
--> Your team is adopting a multi-cloud strategy, and you need to manage resources on both AWS and Azure using Terraform. 
How would you structure your Terraform code to handle this?

For a multi-cloud setup, I use separate provider blocks for AWS and Azure, and organize my Terraform code using modules and environment folders.
Each cloud will have its own module (like AWS-network, Azure-network, etc.), and then I call them from a common root module or environment-specific folder.
This way, we can manage both clouds with the same Terraform workflow but keep their configurations isolated.”
Why this structure?
Isolation: Keeps AWS and Azure code separate and easy to maintain.
Reusability: Modules can be reused across environments.
Scalability: Easy to add new clouds later.
Separation of state: Each provider can have its own backend (e.g., S3 for AWS, Azure Storage for Azure).
--------------------------------------------------------------------------------------------------------------------------------------------------
-->  You want to run specific scripts after provisioning resources with Terraform. How would you achieve this, and what provisioners might you use?

In Terraform, we use provisioners to run actions or scripts after a resource is created.
The main provisioners are file, remote-exec, and local-exec.
file is used to upload files or scripts to a remote instance.
remote-exec runs commands or shell scripts on the remote instance.
local-exec runs commands on the local machine where Terraform is executed — for example, triggering a CI/CD script or Ansible playbook.”
 provisioner "file" {
    source      = "install_nginx.sh"
    destination = "/tmp/install_nginx.sh"
  }

  # Execute script on the instance
  provisioner "remote-exec" {
    inline = [
      "chmod +x /tmp/install_nginx.sh",
      "sudo /tmp/install_nginx.sh"
    ]
  }

  # Execute command locally after provisioning
  provisioner "local-exec" {
    command = "echo 'Instance created successfully' >> output.log"
  }

  connection {
    type        = "ssh"
    user        = "ec2-user"
    private_key = file("~/.ssh/id_rsa")
    host        = self.public_ip
  }
-------------------------------------------------------------------------------------------------------------------------------------------------
--> You are dealing with sensitive information, such as API keys, in your Terraform configuration. What approach would you take to manage these securely?

In Terraform, I never hardcode sensitive values like API keys or passwords in the configuration files.
I store them securely in secret management services such as AWS Secrets Manager or Azure Key Vault, and then fetch them dynamically during Terraform execution.
This prevents secrets from being exposed in code or state files.”

Other Best Practices to Mention:
Use Terraform variables with sensitive = true to hide output values.
Store variables in .tfvars or environment variables, not in main.tf.
Use remote backends (S3/Azure Storage) with encryption enabled.
Never commit secrets to version control (use .gitignore).

---------------------------------------------------------------------------------------------------------------------------------------------------
--> Describe a scenario where you might need to use Terraform workspaces, and how would you structure your project to take advantage of them?

“We use Terraform workspaces when we want to manage multiple environments (like dev, test, and prod) using the same codebase, but with separate state files.
Each workspace maintains its own isolated state, so changes in one environment don’t affect others.”

Advantages:
No need to duplicate code for multiple environments.
Each environment has an isolated state file.
Easy to switch between environments with one command.
Perfect for smaller teams or simple multi-env setups.
-------------------------------------------------------------------------------------------------------------------------------------------------------------
--> You've made changes to your Terraform configuration, and now you want to preview the execution plan before applying the changes. How would you do this?

“In Terraform, before applying any changes, I use the terraform plan command to preview what actions Terraform will take — like what resources will be created, updated, or destroyed.
It helps to verify the configuration and avoid unexpected changes before applying.”

Example Command:
terraform plan
To save the plan to a file (for approval or CI/CD):
terraform plan -out=tfplan

To apply that saved plan later:
terraform apply tfplan
Why We Use It:
To preview infrastructure changes safely.
To validate before applying in production.
To share the plan file in team approvals or pipelines.
---------------------------------------------------------------------------------------------------------------------------------------------------------
--> Your team has decided to adopt GitOps practices for managing infrastructure with Terraform. How would you integrate Terraform 
with version control systems like Git?

“In a GitOps setup, we integrate Terraform with Git by storing all Terraform configuration files (.tf) in a Git repository.
Any change to the infrastructure goes through pull requests, which are reviewed and approved before being merged.
Once merged, a CI/CD pipeline (like GitHub Actions, Azure DevOps, or Jenkins) automatically runs terraform init, terraform plan, and terraform apply to deploy the infrastructure.”

Example Workflow:

Developer creates a feature branch and updates Terraform code.

Runs locally:

terraform fmt
terraform validate
terraform plan


Opens a Pull Request (PR) for review.

When PR is merged to main, a pipeline triggers automatically:

terraform init
terraform plan -out=tfplan
terraform apply -auto-approve tfplan
--------------------------------------------------------------------------------------------------------------------------------------------------
--> Terraform vault?

Terraform Vault refers to HashiCorp Vault, a secret management tool developed by the same company that made Terraform.
It helps to store, generate, and manage secrets dynamically and securely, like database passwords, API tokens, or cloud credentials.
Terraform integrates with Vault through the Vault provider, allowing Terraform to fetch or generate secrets at 
runtime instead of hardcoding them.
When Do We Use Vault?

You use Vault when:
You need to manage secrets across multiple clouds (AWS, Azure, GCP).
You want dynamic secrets (temporary credentials that expire automatically).
You need centralized, fine-grained access control for secrets.
Your organization prefers an on-prem or hybrid security model, not tied to one cloud.

| Feature             | **HashiCorp Vault**                                      | **AWS Secrets Manager**        | **Azure Key Vault**   |
| ------------------- | -------------------------------------------------------- | ------------------------------ | --------------------- |
| **Scope**           | Multi-cloud & On-prem                                    | AWS only                       | Azure only            |
| **Secret Types**    | Static & Dynamic (temporary creds)                       | Static                         | Static                |
| **Integration**     | Works with Terraform, Ansible, Jenkins, Kubernetes, etc. | AWS-specific                   | Azure-specific        |
| **Access Control**  | Detailed, policy-based ACL                               | IAM roles/policies             | RBAC                  |
| **Secret Rotation** | Automatic, customizable                                  | Automatic for limited services | Manual or event-based |
| **Dynamic Secrets** | ✅ Yes (DB creds, AWS tokens, etc.)                       | ❌ No                           | ❌ No                  |

provider "vault" {
  address = "https://vault.company.com"
  token   = var.vault_token
}

# Reading secret from Vault
data "vault_generic_secret" "db_creds" {
  path = "secret/data/db"
}

resource "aws_db_instance" "example" {
  engine     = "mysql"
  username   = data.vault_generic_secret.db_creds.data["username"]
  password   = data.vault_generic_secret.db_creds.data["password"]
}
------------------------------------------------------------------------------------------------------------------------------------------------------
--> Your team wants to ensure that the infrastructure is consistently provisioned across multiple environments. 
How would you implement a consistent environment configuration?

workspace, modules, variables
---------------------------------------------------------------------------------------------------------------------------------------------------
--> You are tasked with migrating your existing infrastructure from Terraform v0.11 to v0.12. What considerations and steps would you take?

“When upgrading from Terraform v0.11 to v0.12, I first review the Terraform upgrade guides because v0.12 introduced major 
syntax and language improvements, like first-class expressions, for loops, and better type handling.
I take a backup of the state file, update Terraform to v0.12, and then use the terraform 0.12upgrade command to automatically 
rewrite and validate the configurations.”

Step-by-Step Migration Process:

Backup Everything
Take backups of all .tf files and the current terraform.tfstate file.
Example:
cp terraform.tfstate terraform.tfstate.backup
Install Terraform v0.12
Update Terraform to version 0.12 on your system or CI/CD pipeline.
Run the Upgrade Tool
Terraform provides a built-in helper:
terraform 0.12upgrade
This command scans all .tf files and updates deprecated syntax (like interpolation, variable usage, etc.).

Validate the Configuration
terraform validate
Run Plan and Compare
terraform plan
terraform apply
-----------------------------------------------------------------------------------------------------------------------------------------------------
--> Explain a situation where you might need to use terraform taint and what effect it has on resources?

“We use terraform taint when a resource becomes corrupted or manually changed outside of Terraform — like when someone changes 
settings in the Azure portal or AWS console.By using terraform taint, we can mark that specific resource for recreation without 
affecting other resources.
For example, if someone manually changed the Azure VM size in the portal, I’ll run:

terraform taint azurerm_virtual_machine.appvm
terraform apply

After tainting, Terraform destroys and recreates only that resource based on the configuration in the code.
This helps to:
Prevent configuration drift between Terraform and the actual cloud setup.
Avoid manual fixes or deleting everything.
Keep the infrastructure consistent with the Terraform state file.
In short, terraform taint is used to repair or replace a broken resource safely without impacting the rest of the environment.”
---------------------------------------------------------------------------------------------------------------------------------------------------



