1. How do you handle Kubernetes cluster security?

To secure a Kubernetes cluster, I follow these key practices:
Network Policies
By default, all pods can talk to each other.
I enable Network Policies to restrict communication and only allow required traffic between pods and namespaces.
RBAC (Role-Based Access Control)
I apply the least-privilege principle.
Users, service accounts, and applications get only the permissions they need — no one gets cluster-admin unless required.
Namespaces for Isolation
I use namespaces to separate environments and applications — for example, dev, UAT, prod.
This helps in multi-tenancy, resource control, and security isolation.
Admission Controllers / Pod Security Standards
I enforce Pod Security Policies/Standards like restricted mode.
This blocks privileged containers, root users, and enforces secure defaults during deployment.
Audit Logging
I enable audit logs to monitor cluster activity and detect suspicious actions.
Logs are forwarded to a central monitoring tool for alerts and investigation.

2. How 2 containers running in a single Pod have a single IP address?

Pods share network in Kubernetes
In Kubernetes, containers inside the same Pod share the same network space.
Single IP per Pod
Kubernetes assigns one IP to the Pod, not to each container.
Shared Network Namespace
Containers inside the Pod share the same network namespace, so they use the same IP, same network interface.
Communication via Localhost
Because of shared network, containers talk to each other using localhost (127.0.0.1) and their container ports.
Simple Example
Pod IP = 10.10.5.20
Container A IP = 10.10.5.20
Container B IP = 10.10.5.20
hey talk like:
http://localhost:<port>
                                          [or]
Kubernetes uses a pause container to manage networking for a Pod.
Kubernetes creates a special container called the Pause container for every Pod.
This pause container’s only job is to provide and maintain the network namespace for the Pod.
All the other containers inside the Pod join the same network namespace as the pause container.
Because of this, they share the same:
Pod IP address
Network interface
Localhost network (127.0.0.1)
Port space
Most people don’t notice the pause container, but it is responsible for the Pod’s networking.
It acts like a root container, and all application containers use the network interface created by it.
So, containers in the same Pod share a single virtual network interface and therefore one IP address.

3. What is Service Mesh and why do we need it?

A Service Mesh is a dedicated infrastructure layer that manages communication between microservices in a Kubernetes or cloud-native environment. It ensures that communication between services is secure, reliable, and observable without requiring changes in application code.

A service mesh provides important features such as service discovery, mutual TLS encryption, traffic management, retries, timeouts, load balancing, observability, logging, tracing, authentication, authorization, and circuit-breaker support.

In microservices environments, where services frequently scale, fail, and change dynamically, a service mesh makes communication consistent, secure, and resilient by using sidecar proxies (e.g., Envoy) to handle networking behavior automatically.

4. what are the init containers why do we need it?
5. difference between deployments and statefulsets?

Both Deployments and StatefulSets are used to manage pods, but they are designed for different use cases.
Deployments:
Used for stateless applications like web servers or APIs.
Pods are interchangeable, meaning any pod can replace another.
Supports rolling updates and rollbacks easily.
Pod names are random and IPs are dynamic. 
StatefulSets:
Used for stateful applications like databases (MySQL, Cassandra) that need persistent storage.
Pods are unique and ordered; they maintain a stable identity (persistent hostname and storage).
Supports ordered deployment, scaling, and deletion.
Each pod gets a stable network identity and persistent volume.
In short: Use Deployments for stateless apps, and StatefulSets for stateful apps that need stable storage and identity.

6. Services in kubernets?

Before Kubernetes Services, pod IPs kept changing, so apps couldn’t always find each other or share traffic properly.
In Kubernetes, Services provide a stable network layer to access pods.
Pods are ephemeral — their IPs change when they restart or scale.
Services ensure consistent communication between microservices or external users by giving a fixed IP, DNS name, and load-balancing mechanism.
Why do we use Services?
| Purpose              | Reason                                            |
| -------------------- | ------------------------------------------------- |
| Stable communication | Pods IP changes → Service gives permanent IP/DNS  |
| Load balancing       | Distributes traffic across multiple pods          |
| Service discovery    | Other services find your app using DNS            |
| Expose apps          | Allow internal or external access to applications |

Types of Kubernetes Services with Examples:
ClusterIP (Default):
ClusterIP is the default Kubernetes service type that provides a stable internal IP to access pods inside the cluster.
Since pod IPs change when they restart, ClusterIP ensures reliable internal communication between microservices like frontend → backend → database, and also load-balances traffic across pods.
ex:
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  type: ClusterIP
  selector:
    app: backend
  ports:
  - port: 80
    targetPort: 8080

| Field              | Meaning                                                          |
| ------------------ | ---------------------------------------------------------------- |
| `targetPort: 8080` | **Application container port** (where the app runs inside pod)   |
| `port: 80`         | **ClusterIP service port** (internal stable port other pods use) |

App runs inside the container on 8080
Service exposes it internally on 80
Other pods call service like:
http://backend-service:80
Service then forwards traffic internally to:
PodIP:8080
$ kubectl get svc
NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
backend-service   ClusterIP   10.96.120.45    <none>        80/TCP    5m

NodePort:

NodePort exposes a service outside the cluster by opening a static port on every node.
Users can access the application using <NodeIP>:NodePort.
Internally, NodePort forwards traffic to ClusterIP → Pods.

apiVersion: v1
kind: Service
metadata:
  name: frontend-service
spec:
  type: NodePort
  selector:
    app: frontend
  ports:
  - port: 80
    targetPort: 3000
    nodePort: 32080

| Field              | Meaning                 |
| ------------------ | ----------------------- |
| `targetPort: 3000` | App inside pod          |
| `port: 80`         | ClusterIP internal port |
| `nodePort: 32080`  | Public access via node  |

http://<Node-IP>:32080
kubectl get svc
NAME              TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)           AGE
frontend-service  NodePort    10.96.170.22   <none>        80:32080/TCP      5m

LoadBalancer
LoadBalancer exposes a service to the internet using a cloud provider’s load balancer (AWS ELB, Azure LB, GCP LB).
Good for production external traffic.

apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  type: LoadBalancer
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080

| Field              | Meaning                       | Explanation                                                |
| ------------------ | ----------------------------- | ---------------------------------------------------------- |
| `targetPort: 3000` | **Pod/Container port**        | App inside the pod runs on **3000**                        |
| `port: 80`         | **Service/LoadBalancer port** | Service exposes port **80** to the world & forwards to pod |


http://<EXTERNAL-IP>:80

NAME          TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)       AGE
web-service   LoadBalancer   10.96.200.21   34.92.10.50     80:32400/TCP  5m






